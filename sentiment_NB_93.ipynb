{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3o-doWBGW12r",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "03e05826-009d-42d2-dfe5-39fd1f2626d5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data =pd.read_csv(r'/content/cleaned_tweets (3).csv')\n",
    "data.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "Z1n__4n4Q0dm",
    "outputId": "07609873-8934-4651-d649-5b5b6e407390"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \\\n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)   \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)   \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)   \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)   \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)   \n",
       "\n",
       "                                          final_text  \\\n",
       "0                                          what said   \n",
       "1    plus you have added commercial experience tacky   \n",
       "2  i did not today must mean i need take another ...   \n",
       "3  bad flight it is really aggressive blast obnox...   \n",
       "4          ca not tell it is really big bad thing it   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0                                          what said   \n",
       "1    plus you have added commercial experience tacky   \n",
       "2  i did not today must mean i need take another ...   \n",
       "3  bad flight it is really aggressive blast obnox...   \n",
       "4          ca not tell it is really big bad thing it   \n",
       "\n",
       "                                              tokens  \n",
       "0                                   ['what', 'said']  \n",
       "1  ['plus', 'you', 'have', 'added', 'commercial',...  \n",
       "2  ['i', 'did', 'not', 'today', 'must', 'mean', '...  \n",
       "3  ['bad', 'flight', 'it', 'is', 'really', 'aggre...  \n",
       "4  ['ca', 'not', 'tell', 'it', 'is', 'really', 'b...  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-cbf5dd8c-ceb7-4093-8848-4bc2bbb3c450\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>final_text</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>what said</td>\n",
       "      <td>what said</td>\n",
       "      <td>['what', 'said']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>plus you have added commercial experience tacky</td>\n",
       "      <td>plus you have added commercial experience tacky</td>\n",
       "      <td>['plus', 'you', 'have', 'added', 'commercial',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>i did not today must mean i need take another ...</td>\n",
       "      <td>i did not today must mean i need take another ...</td>\n",
       "      <td>['i', 'did', 'not', 'today', 'must', 'mean', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>bad flight it is really aggressive blast obnox...</td>\n",
       "      <td>bad flight it is really aggressive blast obnox...</td>\n",
       "      <td>['bad', 'flight', 'it', 'is', 'really', 'aggre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>ca not tell it is really big bad thing it</td>\n",
       "      <td>ca not tell it is really big bad thing it</td>\n",
       "      <td>['ca', 'not', 'tell', 'it', 'is', 'really', 'b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbf5dd8c-ceb7-4093-8848-4bc2bbb3c450')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-cbf5dd8c-ceb7-4093-8848-4bc2bbb3c450 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-cbf5dd8c-ceb7-4093-8848-4bc2bbb3c450');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-4fc59bb9-e105-4606-9e0c-84e9f816769a\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4fc59bb9-e105-4606-9e0c-84e9f816769a')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-4fc59bb9-e105-4606-9e0c-84e9f816769a button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "data",
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 14640,\n  \"fields\": [\n    {\n      \"column\": \"tweet_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 779111158481836,\n        \"min\": 567588278875213824,\n        \"max\": 570310600460525568,\n        \"num_unique_values\": 14485,\n        \"samples\": [\n          567917894144770049,\n          567813976492417024,\n          569243676594941953\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"airline_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"airline_sentiment_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1628299590986659,\n        \"min\": 0.335,\n        \"max\": 1.0,\n        \"num_unique_values\": 1023,\n        \"samples\": [\n          0.6723,\n          0.3551,\n          0.6498\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negativereason\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Damaged Luggage\",\n          \"Can't Tell\",\n          \"Lost Luggage\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negativereason_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3304397596377413,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1410,\n        \"samples\": [\n          0.6677,\n          0.6622,\n          0.6905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"airline\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Virgin America\",\n          \"United\",\n          \"American\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"airline_sentiment_gold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7701,\n        \"samples\": [\n          \"smckenna719\",\n          \"thisAnneM\",\n          \"jmspool\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negativereason_gold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Customer Service Issue\\nLost Luggage\",\n          \"Late Flight\\nCancelled Flight\",\n          \"Late Flight\\nFlight Attendant Complaints\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweet_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 44,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0,\n          1,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14427,\n        \"samples\": [\n          \"@JetBlue so technically I could drive to JFK now and put in. Request for tomorrow's flight?\",\n          \"@united why I won't check my carry on. Watched a handler throw this bag -- miss the conveyer belt -- sat there 10 min http://t.co/lyoocx5mSH\",\n          \"@SouthwestAir you guys are so clever \\ud83d\\ude03 http://t.co/qn5odUGFqK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_coord\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 832,\n        \"samples\": [\n          \"[40.04915451, -75.10364317]\",\n          \"[32.97609561, -96.53349238]\",\n          \"[26.37852293, -81.78472152]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_created\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 14247,\n        \"samples\": [\n          \"2015-02-23 07:40:55 -0800\",\n          \"2015-02-21 16:20:09 -0800\",\n          \"2015-02-21 21:33:21 -0800\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3081,\n        \"samples\": [\n          \"Oakland, California\",\n          \"Beverly Hills, CA\",\n          \"Austin, TX/NY, NY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_timezone\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"Helsinki\",\n          \"Eastern Time (US & Canada)\",\n          \"America/Detroit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14213,\n        \"samples\": [\n          \"customer service issue how many tree have die you stop trying sell u credit card optout\",\n          \"lost luggage i need go yyz tmr morning 8 am i switched united already my bag is still aa la la land\",\n          \"i would like thank customer service team their response my cancelled flightled flight just offering cont\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14213,\n        \"samples\": [\n          \"customer service issue how many tree have die you stop trying sell u credit card optout\",\n          \"lost luggage i need go yyz tmr morning 8 am i switched united already my bag is still aa la la land\",\n          \"i would like thank customer service team their response my cancelled flightled flight just offering cont\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14214,\n        \"samples\": [\n          \"['quick', 'question', 'let', 'u', 'say', 'i', 'book', 'flight', 'i', 'did', 'so', 'you', 'drop', 'price', 'do', 'i', 'get', 'cheaper', 'rate']\",\n          \"['thank', 'you', 'quick', 'customer', 'service', 'today', 'refundprocedurenottoopainful', 'i', 'know', 'winter', 'weather', 'is', 'not', 'your', 'fault']\",\n          \"['i', 'would', 'like', 'thank', 'customer', 'service', 'team', 'their', 'response', 'my', 'cancelled', 'flightled', 'flight', 'just', 'offering', 'cont']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Separate negative and positive sentiment tweets\n",
    "neg_data = data[data['airline_sentiment'] == 'negative']\n",
    "pos_data = data[data['airline_sentiment'] == 'positive']\n",
    "\n",
    "# Sample an equal number of negative and positive tweets\n",
    "num_samples = min(len(neg_data), len(pos_data))\n",
    "neg_data = neg_data.sample(n=num_samples, random_state=42)\n",
    "pos_data = pos_data.sample(n=num_samples, random_state=42)\n",
    "\n",
    "# Concatenate the negative and positive sentiment tweets\n",
    "balanced_data = pd.concat([neg_data, pos_data])\n",
    "\n",
    "# Shuffle the rows\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42)"
   ],
   "metadata": {
    "id": "4ve3u31p0Q7x"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into features and target\n",
    "X = balanced_data['final_text'].values.tolist()\n",
    "y = balanced_data['airline_sentiment'].values.tolist()\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2, random_state = 42)\n",
    "# Map positive to 1 and negative to 0\n",
    "y_train = [int(sent == 'positive') for sent in y_train]\n",
    "y_test = [int(sent == 'positive') for sent in y_test]\n",
    "def build_freqs(tweets, ys):\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            freqs[pair] = freqs.get(pair, 0) + 1\n",
    "    return freqs\n",
    "    # Calculate the number of tweets, the number of positive tweets, the number of negative tweets\n",
    "T = len(X_train)\n",
    "T_pos = y_train.count(1)\n",
    "T_neg = y_train.count(0)\n",
    "\n",
    "print('Total number of tweets: {}'.format(T))\n",
    "print('Number of positive tweets: {}'.format(T_pos))\n",
    "print('Number of negative tweets: {}'.format(T_neg))\n",
    "# Calculate the probabilities for each class\n",
    "Prob_T_pos = T_pos/T\n",
    "Prob_T_neg = T_neg/T\n",
    "\n",
    "print('Probability of positive class: {}'.format(Prob_T_pos))\n",
    "print('Probability of negative class: {}'.format(Prob_T_neg))\n",
    "# Calculate the number of unique words V\n",
    "vocab = [key[0] for key in freqs.keys()]\n",
    "V = len(set(vocab))\n",
    "\n",
    "print('Number of unique words: {}'.format(V))\n",
    "# Calculate N_pos, N_neg\n",
    "N_pos = 0\n",
    "N_neg = 0\n",
    "\n",
    "for pair in freqs.keys():\n",
    "    # if label is positive\n",
    "    if pair[1] > 0:\n",
    "        N_pos += freqs[pair]\n",
    "    # if label is negative\n",
    "    else:\n",
    "        N_neg += freqs[pair]\n",
    "\n",
    "print(\"Number of positive words for all tweets: {}\".format(N_pos))\n",
    "print(\"Number of negative words for all tweets: {}\".format(N_neg))\n",
    "\n",
    "# Calculation for positive and negative probability of a word. We will do it for the first word in the vocab\n",
    "print('First Word in vocab: {}'.format(vocab[0]))\n",
    "\n",
    "# get positive and negative frequency of word\n",
    "freq_pos = freqs.get((vocab[0],1), 0)\n",
    "freq_neg = freqs.get((vocab[0],0), 0)\n",
    "\n",
    "print('Positive frequency of {} is: {}'.format(vocab[0], freq_pos))\n",
    "print('Negative frequency of {} is: {}'.format(vocab[0], freq_neg))\n",
    "\n",
    "# calculate the probability that the word is positive and negative\n",
    "p_w_pos = (freq_pos + 1)/(N_pos + V)\n",
    "p_w_neg = (freq_neg + 1)/(N_neg + V)\n",
    "\n",
    "print(\"The probability that the word: {} is positive is: {}\".format(vocab[0], p_w_pos))\n",
    "print(\"The probability that the word: {} is negative is: {}\".format(vocab[0], p_w_neg))\n",
    "# calculate the log likelihood of the word\n",
    "loglikelihood = np.log(p_w_pos/ p_w_neg)\n",
    "\n",
    "print(\"The log likelihood of the word: {} is: {}\".format(vocab[0], loglikelihood))\n",
    "def train_naive(freqs, X_train, y_train):\n",
    "\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    # Calculate the number of unique words V\n",
    "    vocab = [key[0] for key in freqs.keys()]\n",
    "    V = len(set(vocab))\n",
    "\n",
    "    # Calculate N_pos, N_neg\n",
    "    N_pos = 0\n",
    "    N_neg = 0\n",
    "\n",
    "    for pair in freqs.keys():\n",
    "        # if label is positive\n",
    "        if pair[1] > 0:\n",
    "            N_pos += freqs[pair]\n",
    "        # if label is negative\n",
    "        else:\n",
    "            N_neg += freqs[pair]\n",
    "\n",
    "    # Calculate the number of tweets, the number of positive tweets, the number of negative tweets\n",
    "    T = len(X_train)\n",
    "    T_pos = y_train.count(1)\n",
    "    T_neg = y_train.count(0)\n",
    "\n",
    "    # Calculate the logprior\n",
    "    logprior = np.log(T_pos) - np.log(T_neg)\n",
    "\n",
    "    # for each word in the vocabulary\n",
    "    for word in vocab:\n",
    "        # get positive and negative frequency of word\n",
    "        freq_pos = freqs.get((word,1), 0)\n",
    "        freq_neg = freqs.get((word,0), 0)\n",
    "\n",
    "        # calculate the probability that the word is positive and negative\n",
    "        p_w_pos = (freq_pos + 1)/(N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1)/(N_neg + V)\n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_pos/ p_w_neg)\n",
    "\n",
    "    return logprior, loglikelihood\n",
    "\n",
    "    logprior, loglikelihood = train_naive(freqs, X_train, y_train)\n",
    "    # Print the first five key-value pairs of loglikelihood\n",
    "count = 0\n",
    "for key, value in loglikelihood.items():\n",
    "    if count < 5:\n",
    "        print(key, value)\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "        def predict_naive(tweet, logprior, loglikelihood):\n",
    "\n",
    "    # process tweet to return list of cleaned words\n",
    "    words = process_tweet(tweet)\n",
    "\n",
    "    # intialize the probability to 0\n",
    "    p = 0\n",
    "\n",
    "    # add the logprior\n",
    "    p += logprior\n",
    "\n",
    "    # iterate over each word in tweet\n",
    "    for word in words:\n",
    "        # check if word in loglikelihood dictionary\n",
    "        if word in loglikelihood:\n",
    "            # add the loglikelihood value of the word to the probability\n",
    "            p += loglikelihood[word]\n",
    "\n",
    "    return p\n",
    "    # test on some random string\n",
    "random_test = 'I am very happy today :)'\n",
    "predict_naive(random_test, logprior, loglikelihood)\n",
    "# initialize prediction list\n",
    "y_preds = []\n",
    "\n",
    "for tweet in X_test:\n",
    "    # if prediction is positive, append 1 to y_preds\n",
    "    if predict_naive(tweet, logprior, loglikelihood) > 0:\n",
    "        y_preds.append(1)\n",
    "    # if prediction is negative, append 0 to y_preds\n",
    "    else:\n",
    "        y_preds.append(0)"
   ],
   "metadata": {
    "id": "3AAh98y1fnK2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Map positive to 1 and negative to 0\n",
    "y_train = [int(sent == 'positive') for sent in y_train]\n",
    "y_test = [int(sent == 'positive') for sent in y_test]"
   ],
   "metadata": {
    "id": "W6k9lXVLzp6l"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def build_freqs(tweets, ys):\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            freqs[pair] = freqs.get(pair, 0) + 1\n",
    "    return freqs"
   ],
   "metadata": {
    "id": "EXfM9FZ70mt2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the number of tweets, the number of positive tweets, the number of negative tweets\n",
    "T = len(X_train)\n",
    "T_pos = y_train.count(1)\n",
    "T_neg = y_train.count(0)\n",
    "\n",
    "print('Total number of tweets: {}'.format(T))\n",
    "print('Number of positive tweets: {}'.format(T_pos))\n",
    "print('Number of negative tweets: {}'.format(T_neg))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3D8WiyM0tCv",
    "outputId": "bd7fa3e6-a68c-4043-b72f-2481266d6e36"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of tweets: 3780\n",
      "Number of positive tweets: 1877\n",
      "Number of negative tweets: 1903\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the probabilities for each class\n",
    "Prob_T_pos = T_pos/T\n",
    "Prob_T_neg = T_neg/T\n",
    "\n",
    "print('Probability of positive class: {}'.format(Prob_T_pos))\n",
    "print('Probability of negative class: {}'.format(Prob_T_neg))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s77vwDBP0v-0",
    "outputId": "b465f160-0b94-43b6-e522-385d8dc8c2dc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Probability of positive class: 0.49656084656084654\n",
      "Probability of negative class: 0.5034391534391535\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the number of unique words V\n",
    "vocab = [key[0] for key in freqs.keys()]\n",
    "V = len(set(vocab))\n",
    "\n",
    "print('Number of unique words: {}'.format(V))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRZK1NJl0zry",
    "outputId": "cc3493b9-6467-41a5-c143-3cec45d4ff08"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of unique words: 4617\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate N_pos, N_neg\n",
    "N_pos = 0\n",
    "N_neg = 0\n",
    "\n",
    "for pair in freqs.keys():\n",
    "    # if label is positive\n",
    "    if pair[1] > 0:\n",
    "        N_pos += freqs[pair]\n",
    "    # if label is negative\n",
    "    else:\n",
    "        N_neg += freqs[pair]\n",
    "\n",
    "print(\"Number of positive words for all tweets: {}\".format(N_pos))\n",
    "print(\"Number of negative words for all tweets: {}\".format(N_neg))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezRD_y2_02tr",
    "outputId": "47de47d8-9c47-491a-a973-643246b8eab4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of positive words for all tweets: 14235\n",
      "Number of negative words for all tweets: 24460\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculation for positive and negative probability of a word. We will do it for the first word in the vocab\n",
    "print('First Word in vocab: {}'.format(vocab[0]))\n",
    "\n",
    "# get positive and negative frequency of word\n",
    "freq_pos = freqs.get((vocab[0],1), 0)\n",
    "freq_neg = freqs.get((vocab[0],0), 0)\n",
    "\n",
    "print('Positive frequency of {} is: {}'.format(vocab[0], freq_pos))\n",
    "print('Negative frequency of {} is: {}'.format(vocab[0], freq_neg))\n",
    "\n",
    "# calculate the probability that the word is positive and negative\n",
    "p_w_pos = (freq_pos + 1)/(N_pos + V)\n",
    "p_w_neg = (freq_neg + 1)/(N_neg + V)\n",
    "\n",
    "print(\"The probability that the word: {} is positive is: {}\".format(vocab[0], p_w_pos))\n",
    "print(\"The probability that the word: {} is negative is: {}\".format(vocab[0], p_w_neg))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Z5qI7Dy04tj",
    "outputId": "31632b85-868b-4a06-80a0-3c45bc943bb3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First Word in vocab: anoth\n",
      "Positive frequency of anoth is: 24\n",
      "Negative frequency of anoth is: 53\n",
      "The probability that the word: anoth is positive is: 0.0013261192446424783\n",
      "The probability that the word: anoth is negative is: 0.001857137944079513\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# calculate the log likelihood of the word\n",
    "loglikelihood = np.log(p_w_pos/ p_w_neg)\n",
    "\n",
    "print(\"The log likelihood of the word: {} is: {}\".format(vocab[0], loglikelihood))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBDM22A307sC",
    "outputId": "9442d50e-9c24-4975-d9a3-be59cebcc44f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The log likelihood of the word: anoth is: -0.33677974710036085\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def train_naive(freqs, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        freqs: dictionary {(word, label): count}\n",
    "        X_train: list of tweets\n",
    "        y_train: list of labels\n",
    "    Outputs:\n",
    "        logprior: the log prior value\n",
    "        loglikelihood: log likelihood of the Naive Bayes Equation.\n",
    "    \"\"\"\n",
    "\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    # Calculate the number of unique words V\n",
    "    vocab = [key[0] for key in freqs.keys()]\n",
    "    V = len(set(vocab))\n",
    "\n",
    "    # Calculate N_pos, N_neg\n",
    "    N_pos = 0\n",
    "    N_neg = 0\n",
    "\n",
    "    for pair in freqs.keys():\n",
    "        # if label is positive\n",
    "        if pair[1] > 0:\n",
    "            N_pos += freqs[pair]\n",
    "        # if label is negative\n",
    "        else:\n",
    "            N_neg += freqs[pair]\n",
    "\n",
    "    # Calculate the number of tweets, the number of positive tweets, the number of negative tweets\n",
    "    T = len(X_train)\n",
    "    T_pos = y_train.count(1)\n",
    "    T_neg = y_train.count(0)\n",
    "\n",
    "    # Calculate the logprior\n",
    "    logprior = np.log(T_pos) - np.log(T_neg)\n",
    "\n",
    "    # for each word in the vocabulary\n",
    "    for word in vocab:\n",
    "        # get positive and negative frequency of word\n",
    "        freq_pos = freqs.get((word,1), 0)\n",
    "        freq_neg = freqs.get((word,0), 0)\n",
    "\n",
    "        # calculate the probability that the word is positive and negative\n",
    "        p_w_pos = (freq_pos + 1)/(N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1)/(N_neg + V)\n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_pos/ p_w_neg)\n",
    "\n",
    "    return logprior, loglikelihood"
   ],
   "metadata": {
    "id": "klyTuZTz1Ar_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "logprior, loglikelihood = train_naive(freqs, X_train, y_train)"
   ],
   "metadata": {
    "id": "UYQz4cWb1Fl9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Calculate Logprior: {}\".format(logprior))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juk78r3j1ICx",
    "outputId": "e7cfd8bd-a34a-4fcc-cf55-5f3f89c8eca4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculate Logprior: -0.01375683070964051\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Print the first five key-value pairs of loglikelihood\n",
    "count = 0\n",
    "for key, value in loglikelihood.items():\n",
    "    if count < 5:\n",
    "        print(key, value)\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oM_szbs1OK8",
    "outputId": "5b421761-cc0f-4f7a-83d2-c25e4c83f678"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "anoth -0.33677974710036085\n",
      "awesom 4.206089412690352\n",
      "telephon 0.4333284745957127\n",
      "experi 0.3155454389393292\n",
      "thank 2.8727727503069556\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_naive(tweet, logprior, loglikelihood):\n",
    "    \"\"\"\n",
    "    Predict the sentiment of tweet\n",
    "\n",
    "    Inputs:\n",
    "        tweet: string\n",
    "        logprior: number\n",
    "        loglikelihood: dictionary {'word': loglikelihood_value}\n",
    "    Outputs:\n",
    "        p: sum of all the loglikelihood of the words that appear in the tweet plus the logprior value.\n",
    "    \"\"\"\n",
    "    # process tweet to return list of cleaned words\n",
    "    words = process_tweet(tweet)\n",
    "\n",
    "    # intialize the probability to 0\n",
    "    p = 0\n",
    "\n",
    "    # add the logprior\n",
    "    p += logprior\n",
    "\n",
    "    # iterate over each word in tweet\n",
    "    for word in words:\n",
    "        # check if word in loglikelihood dictionary\n",
    "        if word in loglikelihood:\n",
    "            # add the loglikelihood value of the word to the probability\n",
    "            p += loglikelihood[word]\n",
    "\n",
    "    return p"
   ],
   "metadata": {
    "id": "TBIClYJA1QAd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test on some random string\n",
    "random_test = 'I am very happy today :)'\n",
    "predict_naive(random_test, logprior, loglikelihood)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQO38S0L1SRh",
    "outputId": "2133ee67-2806-4e69-b834-a0cde061b7b9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "np.float64(1.8747427352613122)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# initialize prediction list\n",
    "y_preds = []\n",
    "\n",
    "for tweet in X_test:\n",
    "    # if prediction is positive, append 1 to y_preds\n",
    "    if predict_naive(tweet, logprior, loglikelihood) > 0:\n",
    "        y_preds.append(1)\n",
    "    # if prediction is negative, append 0 to y_preds\n",
    "    else:\n",
    "        y_preds.append(0)"
   ],
   "metadata": {
    "id": "RvbaRX_Y1UcG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# calculate the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test = y_test\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_preds)\n",
    "\n",
    "print(\"The accuracy of the Naives Bayes Model is: {}\".format(accuracy))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4OwYymH1Wgf",
    "outputId": "32dcc2d9-a3ce-46b1-83a8-e4e1d71375c5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The accuracy of the Naives Bayes Model is: 0.9312896405919662\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_preds))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVyEKtGoLQ3k",
    "outputId": "30a2626e-68dc-4a31-f82f-c6bdfea1cad6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       460\n",
      "           1       1.00      0.87      0.93       486\n",
      "\n",
      "    accuracy                           0.93       946\n",
      "   macro avg       0.94      0.93      0.93       946\n",
      "weighted avg       0.94      0.93      0.93       946\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "iQFcwXEWb70S"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}